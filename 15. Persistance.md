# Persistance
---
## Structure of I/O Device  
![image](https://user-images.githubusercontent.com/71700079/169822081-1234bc60-e8f3-4c19-90f8-882c84dd7c51.png)  

## Typical I/O Device  
![image](https://user-images.githubusercontent.com/71700079/169822176-a95c770a-8e51-491e-ad87-ea0f47eed744.png)  
- 보통의 I/O 장치들은 위와 같은 구조를 따른다.
- Hardware Interface 부분이 System Software가 연산을 제어하도록 허가한다.
  - Hardware Interface의 3가지 Register들을 통해서 Read/Write를 한다.
- Internals 부분은 그 자체로 구체적으로 구현이 되어있다. (ex)

### Status Check
> Status Register을 Check 함으로써, Device의 상태를 확인한다.  
- Polling : Hardware의 상태를 Check하기 위한 방법.
  - I/O를 요청한 뒤, Disk에서 작업을 하는 동안 Spin-wait을 한다.
  - 이 때 Status Register의 값은 Polling. Disk 작업이 끝나면 다시 하던 Task로 돌아간다.
  - 이 때의 Spin-wait는 매우 시간낭비임을 알 수 있다.
- Interrupt : Polling의 개선 방안.
  - I/O를 요청한 뒤, Disk에서 작업을 하는 동안 다른 Task로 Context Switch를 한다.
  - Disk 작업이 종료되면, 다시 Wait하던 Task를 깨우고 돌아간다.
  - 하지만 Interrupts가 만능은 아니다.
    - 어떤 Device가 속도가 너무 빨라서 오히려 Context Switch의 Overhead가 더 크다면,
    - 즉 Device가 충분히 빠르다면 Polling이 더 이득일 것이다.

### Data Transfer
> Data를 전송하는데에 있어서의 2가지 방법  
- Programmed I/O : CPU가 직접 I/O 작업에 관여한다.
  - CPU가 I/O가 완료되었는지 상태 플래그를 계속 조사해야하며, 그 동안 CPU는 다른 일을 할 수 없다.
  - Data 전송도 CPU가 직접 처리하므로 Memory에서 Device로 Data를 Copy하는 시간 또한 매우 큰 Overhead이다.
- DMA(Direct Memory Access) : CPU는 더 이상 관여하지 않는다.
  - CPU는 I/O에 필요한 정보를 DMA에게 보내어, I/O를 개시시킨다.(I/O 장치의 주소, Memory의 시작주소, Command etc..)
  - CPU는 DMA에게 I/O를 맡기고 다른 작업이 가능하다.
    - Cycle Stealing 방식을 이용해서 야금야금 전송한다.
  - CPU를 거치지 않고 바로 Memory로 전송하기 때문에 CPU에 부담이 전혀 없다.
  - I/O 작업 종료시 Interrupt를 발생시켜 CPU에게 바로 알려준다.

### Device Interaction
> 장치와 OS는 어떻게 통신을 할 것인가?  
- Solutions
  - I/O Instructions : 특정 Device Register에게 Data를 전송하기 위한 특수 명령어.
    - ex) in, out (x86)
  - Memory-Mapped I/O
    - 이 경우에는 I/O가 Memory 공간을 차지하게 된다.
    - 즉 CPU는 Memory에 접근하는 것과 같은 기계어 명령어를 통해 I/O 데이터 전송이 가능하다.

### Build Device-Neutral OS
> 모든 장치에 구애받지 않고 적용 가능한 OS는 어떻게 구현이 가능할까?  
- Abstraction : 추상화를 통해서 가능하다.
  - 추상화를 하게 되면, 운영체제의 Layer들이 분리가 된다.
  - 장치들이 갖는 공통점을 모아서 Interface를 만들어 주고, 그 Interface만 가지고 작업이 가능하도록 한다.
  - 추상화가 없다면, 윗 Layer가 수정되면 아래의 모든 Layer가 동시에 수정이 되어야 하는 번거로움이 발생한다.
- I/O stack(Layer)  
![image](https://user-images.githubusercontent.com/71700079/169827097-b44900e0-83be-48de-984b-5522a3e56c33.png)  
  - Device Drivers : 장치의 Register을 세팅하고 상태를 점검하는 Layer이다.

#### Device Drivers
> 추상화 된 계층에서 HW와 SW를 구분하는 핵심적인 Layer이다.  
- Implementation
  - Kernel 안에 포함이 되는 경우(Static Library) : 새로운 Device를 만들 때마다 계속 OS를 새로 설치해야한다.
  - 보통 동적으로 Boot time에 Load 되던가, 실제로 Device가 실행될 때에 Load 하도록 동적으로 설계 되어있다.
- Limit
  - 너무나도 많은 특징의 Device들이 존재하며, 각자 모두 다른 Protocol을 갖고 있다.
  - 매우매우 특수한 기능을 제공하는 Device의 경우 추상화가 되어버리면, 해당 기능을 못쓰게 될 수가 있다.
  - 시대가 점점 발전할 수록 Device Driver의 Code가 OS Code의 70% 이상을 차지하게 되어간다.
    - 이는 곧 모든 Driver을 관리하기가 어려워 졌다는 말이다.

## HDD
> Secondary Storage.  
> Main Memory의 보조 기억 장치로 사용되는 HDD이다.  

- Data를 저장할 수 있지만, Memory Bus에 바로 연결이 되어있지 않다.
  - 따라서 바로 CPU로 전송할 수 없고 반드시 Memory를 거쳐야 한다.
- Byte 단위로 읽어들일 수 없다.
  - 512Byte or 4KByte의 Sector 단위로 Data를 읽고 전송한다.
- 용량이 매우 크며, 싸고 느리다.
- Non-volatile(Persistent)

### HDD Architecture  
![image](https://user-images.githubusercontent.com/71700079/169828182-89284e78-07b2-478b-b3b0-a00df0e4714b.png)  
- Head가 돌면서 특정 Track에 위치하는 행동을 __Seek__ 라고 한다.
- Seek를 통해 놓인 Track에서 정확한 Sector을 찾아가는 일을 __Rotation__ 이라고 한다.
- 정확한 Sector에서 Data를 읽고 전송하는 일을 __Transfer__ 이라고 한다.
  - Seek Time > Rotation Time > Transfer Time (보통은 이러하다)  
![image](https://user-images.githubusercontent.com/71700079/169828467-38b511e8-ed02-4c68-8018-a4291a004efb.png)  

## Disk Scheduling
> Disk의 Data 양은 매우 방대하기 때문에, 최대한 시간 손해를 보지 않으면서 Data가 저장된 위치를 탐색해야한다.  
> 그러기 위해서는 적절한 방법을 통한 Scheduling이 필요할 것이다.  
- Work Conserving : 다음 작업이 있다면, 곧바로 달려가서 처리하는 Scheduling
- Non-work Conserving : 다음 작업으로 가기 전에 잠깐 기다리며 더 가까운 곳에서 작업이 발생하는지 살펴보는 Scheduling

### FCFS
> First Come First Served  
- FIFO와 동일한 방식이다.
  - 당연히 매우 비효율적이다.  
  ![image](https://user-images.githubusercontent.com/71700079/169828837-d5a0d980-7195-4d2b-b7e0-ff99d854d84c.png)  
  
### SSTF(Shortest Seek Time First)
> Seek Time을 최소화 시키는 방향으로 작동한다.  
- 가장 가까운(동일한 Track) Data부터 순서대로 처리한다.
  - 이는 Starvation을 불러올 수 있다. (너무 멀면 거기로 처리하러 안 감)  
  ![image](https://user-images.githubusercontent.com/71700079/169829117-f868ef92-ee37-4faf-b2bc-5afa8bb74ca0.png)  
- Nearest Block First
  - SSTF와 유사하지만, 이 방식은 OS는 같은 Track인지 아닌지 알 수 없다는 점을 이용해 Sector Number만을 보고 차이가 적은 Number로 이동한다.  

### SCAN
> 가는 길에 작업이 있으면 처리한다.  
- 한 방향으로 죽 갔다가 마지막 Cylinder에 도착하면, 다시 반대방향으로 죽 탐색한다.
  - 가는 길에 요청이 들어온 Sector가 있으면 작업한다.
  - Elevator Algorithm 이라고도 한다.
  - 가운데에 위치한 Data일 수록 접근 가능성 및 응답률이 높아진다.
- C-SCAN(Circular Scan)
  - 반대방향으로 돌지 않고, 한 방향으로만 탐색을 한다.
  - 반대방향으로 돌지 않고 처음부터 다시 탐색을 하기 때문에 원형 Scan이라고 한다.
  - 이렇게 되면 모두 균등한 Wait time을 보장받아 공평해진다.
- F-SCAN(Freeze)
  - 이 방식은 2개의 Queue를 사용한다.
  - 기존 대기 Queue의 요청을 받고 Scan을 시작한 이후에 들어오는 요청들은 다른 Queue에 저장한다.
  - 한 방향으로 SCAN을 진행한 이후에, 반대 방향으로 바꿀 때에 기존 대기 Queue를 __Freeze__ 시키고 다른 Queue로 전환한다.
  - 마찬가지로 이 때 들어오는 요청들은 기존 대기 Queue에 들어가고, 다시 방향이 바뀔 때에 Queue도 바뀐다.

### Modern Disk Scheduling
- Improve Overall Disk Throughput
  - 인접한 Request들을 묶어버려서 Request의 수를 줄인다.
  - Seek time을 줄이기 위해 Requests들을 정렬한다.
- Prevent Starvation : 최대한 모든 Data가 공평하게 요청을 받고 응답할 수 있도록 Fairness를 보장한다.
- Disk Drive
  - OS는 Sector Number만 알고 있는 상황이기 때문에, 어디가 인접한 Sector인지는 정확히 알지 못한다.
  - 따라서 Disk 내부에서 Sector에 대한 구체적 정보를 가지고 Scheduling을 한번 더 진행한다.
